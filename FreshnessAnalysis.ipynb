{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e4aebcd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# **Freshness Analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9c6ebd",
   "metadata": {},
   "source": [
    "# Import neccessary dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "727f2212",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db82e9e6",
   "metadata": {},
   "source": [
    "\n",
    "# Define paths to the training and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "198dd4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data_path = r'C:\\Users\\harsh\\Downloads\\meena\\archive\\dataset\\Train'\n",
    "test_data_path = r'C:\\Users\\harsh\\Downloads\\meena\\archive\\dataset\\Test'\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f87e05",
   "metadata": {},
   "source": [
    "# Data augmentation with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61843229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12355 images belonging to 8 classes.\n",
      "Found 3084 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255,\n",
    "    validation_split=0.2 \n",
    ")\n",
    "\n",
    "# Training and validation generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='training'\n",
    ")\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_data_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47c5656c",
   "metadata": {},
   "source": [
    "# Test data generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224c5414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4713 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1.0 / 255)  # Only rescale for test data\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_path,\n",
    "    target_size=(150, 150),\n",
    "    batch_size=64,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Important to keep the order for evaluation\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7872c9d2",
   "metadata": {},
   "source": [
    "# Print class indices to confirm number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "566a965a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class indices:  {'freshapples': 0, 'freshbanana': 1, 'freshbittergroud': 2, 'freshtomato': 3, 'rottenapples': 4, 'rottenbanana': 5, 'rottenbittergroud': 6, 'rottentomato': 7}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"Class indices: \", train_generator.class_indices)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5786c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load VGG16 model + higher level layers\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(150, 150, 3))\n",
    "\n",
    "# Freeze the base model\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create the hybrid model\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')  # Output layer\n",
    "])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7ad480",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "310f0ed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69982265",
   "metadata": {},
   "source": [
    "# Callbacks for early stopping and learning rate reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09e75b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=2, verbose=1, min_lr=1e-6)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a8018b",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb712899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "386/386 [==============================] - 67s 153ms/step - loss: 0.3001 - accuracy: 0.8980 - val_loss: 0.7247 - val_accuracy: 0.7640 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "386/386 [==============================] - 61s 159ms/step - loss: 0.0985 - accuracy: 0.9666 - val_loss: 0.6695 - val_accuracy: 0.7965 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "386/386 [==============================] - 63s 162ms/step - loss: 0.0742 - accuracy: 0.9741 - val_loss: 0.7269 - val_accuracy: 0.7969 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "386/386 [==============================] - 62s 160ms/step - loss: 0.0660 - accuracy: 0.9754 - val_loss: 0.6612 - val_accuracy: 0.8089 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "386/386 [==============================] - 65s 168ms/step - loss: 0.0561 - accuracy: 0.9805 - val_loss: 0.8077 - val_accuracy: 0.7952 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "386/386 [==============================] - ETA: 0s - loss: 0.0656 - accuracy: 0.9767\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "386/386 [==============================] - 86s 222ms/step - loss: 0.0656 - accuracy: 0.9767 - val_loss: 0.8399 - val_accuracy: 0.8044 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "386/386 [==============================] - 79s 205ms/step - loss: 0.0336 - accuracy: 0.9883 - val_loss: 0.8197 - val_accuracy: 0.7907 - lr: 5.0000e-04\n",
      "Epoch 8/30\n",
      "386/386 [==============================] - ETA: 0s - loss: 0.0223 - accuracy: 0.9924\n",
      "Epoch 8: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "386/386 [==============================] - 73s 189ms/step - loss: 0.0223 - accuracy: 0.9924 - val_loss: 0.9767 - val_accuracy: 0.7956 - lr: 5.0000e-04\n",
      "Epoch 9/30\n",
      "386/386 [==============================] - 75s 194ms/step - loss: 0.0163 - accuracy: 0.9944 - val_loss: 0.9234 - val_accuracy: 0.7962 - lr: 2.5000e-04\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x160044496a0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=30,\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39516156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97/97 [==============================] - 16s 160ms/step - loss: 0.6601 - accuracy: 0.8087\n",
      "Validation Accuracy: 0.81\n",
      "74/74 [==============================] - 39s 435ms/step - loss: 1.0993 - accuracy: 0.8835\n",
      "Test Accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Evaluate the model on the validation set\n",
    "val_loss, val_accuracy = model.evaluate(validation_generator)\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}')\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Test Accuracy: {test_accuracy:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e6e66b5",
   "metadata": {},
   "source": [
    "# Fine-tuning the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba308474-0e64-4ae1-a3a0-47f9d37af94f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "386/386 [==============================] - 75s 189ms/step - loss: 0.1281 - accuracy: 0.9592 - val_loss: 0.7613 - val_accuracy: 0.7868 - lr: 1.0000e-04\n",
      "Epoch 2/15\n",
      "386/386 [==============================] - 68s 177ms/step - loss: 0.0348 - accuracy: 0.9884 - val_loss: 0.8936 - val_accuracy: 0.7832 - lr: 1.0000e-04\n",
      "Epoch 3/15\n",
      "386/386 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9897\n",
      "Epoch 3: ReduceLROnPlateau reducing learning rate to 4.999999873689376e-05.\n",
      "386/386 [==============================] - 70s 181ms/step - loss: 0.0362 - accuracy: 0.9897 - val_loss: 0.8489 - val_accuracy: 0.7979 - lr: 1.0000e-04\n",
      "Epoch 4/15\n",
      "386/386 [==============================] - 71s 185ms/step - loss: 0.0105 - accuracy: 0.9962 - val_loss: 1.0026 - val_accuracy: 0.8324 - lr: 5.0000e-05\n",
      "Epoch 5/15\n",
      "386/386 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9974\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-05.\n",
      "386/386 [==============================] - 70s 182ms/step - loss: 0.0076 - accuracy: 0.9974 - val_loss: 0.8925 - val_accuracy: 0.8558 - lr: 5.0000e-05\n",
      "Epoch 6/15\n",
      "386/386 [==============================] - 69s 179ms/step - loss: 0.0053 - accuracy: 0.9978 - val_loss: 0.8305 - val_accuracy: 0.8639 - lr: 2.5000e-05\n",
      "74/74 [==============================] - 23s 308ms/step - loss: 1.1764 - accuracy: 0.8882\n",
      "Final Test Accuracy after fine-tuning: 0.89\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Unfreeze the last few layers of the base model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:-4]:  # Unfreeze the last 4 layers\n",
    "    layer.trainable = False\n",
    "\n",
    "# Recompile the model with a lower learning rate\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Continue training for additional epochs\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    validation_data=validation_generator,\n",
    "    epochs=15,  # Fewer epochs for fine-tuning\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,\n",
    "    callbacks=[early_stopping, reduce_lr]\n",
    ")\n",
    "\n",
    "# Final evaluation on the test set after fine-tuning\n",
    "test_loss, test_accuracy = model.evaluate(test_generator)\n",
    "print(f'Final Test Accuracy after fine-tuning: {test_accuracy:.2f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7206921b-2fcb-4852-8789-e71bcc3119d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# Assume 'model' is your trained model\n",
    "model.save('trainedModel.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "01281544-2c6b-4f10-b3dd-e8a06471eef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "def classify_image(image_path, model_path):\n",
    "    # Load the pre-trained model\n",
    "    model = load_model(model_path)\n",
    "    \n",
    "    # Load the image file, resizing it to the expected input size of the model (150, 150 in your case)\n",
    "    img = load_img(image_path, target_size=(150, 150))  # Adjusted size here\n",
    "    \n",
    "    # Convert the image to an array and expand dimensions to be suitable for model input\n",
    "    img_array = img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Normalize the image array if required (depending on how the model was trained)\n",
    "    img_array /= 255.0  # Scale the pixel values to [0, 1] if needed\n",
    "    \n",
    "    # Predict the class of the image\n",
    "    prediction = model.predict(img_array)\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    \n",
    "    # Return the predicted class; you might want to adjust this to return a string label\n",
    "    return predicted_class\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc788bb",
   "metadata": {},
   "source": [
    "# Example usage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5f7b17b8-36b5-4fc1-8748-53a23f968425",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = r'C:\\Users\\harsh\\Downloads\\meena\\trainedModel.h5'\n",
    "image_path = r'C:\\Users\\harsh\\Downloads\\meena\\archive\\dataset\\Test\\freshapples\\vertical_flip_Screen Shot 2018-06-08 at 5.07.05 PM.png'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70b0d4ec",
   "metadata": {},
   "source": [
    "# Load the image file, resizing it to the expected input size of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f40639cd-f7c8-43eb-85c4-81fd8410d907",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = load_img(image_path, target_size=(150, 150))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ce4b28dc-0a32-4a6e-b65b-fee948f6f798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 147ms/step\n",
      "Predicted class: [0]\n"
     ]
    }
   ],
   "source": [
    "result = classify_image(image_path, model_path)\n",
    "print(\"Predicted class:\", result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (cuda)",
   "language": "python",
   "name": "cuda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
